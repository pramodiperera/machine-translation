{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMmZZXeuMAO27DthEldzXtL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["#### ***English to French*** "],"metadata":{"id":"EG5mqDraQQ3f"}},{"cell_type":"markdown","source":["**character-level sequence-to-sequence**"],"metadata":{"id":"_aPHQwO2tuU4"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"05Co1Nq8QIPy","executionInfo":{"status":"ok","timestamp":1671188960763,"user_tz":-330,"elapsed":7584,"user":{"displayName":"Pramodi Perera","userId":"07641000018697658769"}}},"outputs":[],"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense\n","import numpy as np"]},{"cell_type":"code","source":["batch_size = 64\n","#epoches = 100\n","latent_dim = 256 # latent dim of encoding space \n","num_samples = 10000 # no of samples to train"],"metadata":{"id":"aqd9ZV2KYO-p","executionInfo":{"status":"ok","timestamp":1671188963047,"user_tz":-330,"elapsed":2,"user":{"displayName":"Pramodi Perera","userId":"07641000018697658769"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ADnQ9DwbY1T","executionInfo":{"status":"ok","timestamp":1671188992308,"user_tz":-330,"elapsed":26816,"user":{"displayName":"Pramodi Perera","userId":"07641000018697658769"}},"outputId":"fa3e323b-ba8d-44f6-bc81-2d443379c5e4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["data_path = '/content/gdrive/My Drive/NLP labs/fra.txt'"],"metadata":{"id":"_42B489Zbrdt","executionInfo":{"status":"ok","timestamp":1671188994992,"user_tz":-330,"elapsed":2,"user":{"displayName":"Pramodi Perera","userId":"07641000018697658769"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["### read the file \n","with open(data_path, 'r', encoding='utf-8') as f:\n","  lines = f.read().split('\\n')\n","\n","lines[:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Ba6lVVVYtyb","executionInfo":{"status":"ok","timestamp":1671188998588,"user_tz":-330,"elapsed":1665,"user":{"displayName":"Pramodi Perera","userId":"07641000018697658769"}},"outputId":"163f28a7-f9cf-40e2-edb8-1543dd5a7e16"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)',\n"," 'Go.\\tMarche.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)',\n"," 'Go.\\tEn route !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8267435 (felix63)']"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["#### read each unique characters\n","\n","input_texts = [] # all english sententces\n","target_texts = [] # all french sententces\n","input_characters = set() # all unique english char.\n","target_characters = set() # all unique french char.\n","\n","for line in lines[: min(num_samples, len(lines)-1)]:\n","  input_text, target_text, _ = line.split('\\t')\n","  #'\\t' as the start seq character, '\\n' as the end seq character\n","  target_text = '\\t' + target_text + '\\n' \n","  input_texts.append(input_text)\n","  target_texts.append(target_text) \n","\n","  for char in input_text:\n","    if char not in input_characters:\n","      input_characters.add(char)\n","  for char in target_text:\n","    if char not in target_characters:\n","      target_characters.add(char)"],"metadata":{"id":"Ujbs_7nRdjT8","executionInfo":{"status":"ok","timestamp":1671189001488,"user_tz":-330,"elapsed":2,"user":{"displayName":"Pramodi Perera","userId":"07641000018697658769"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#### summary\n","input_characters = sorted(list(input_characters))\n","target_characters = sorted(list(target_characters))\n","num_encoder_tokens = len(input_characters)\n","num_decoder_tokens = len(target_characters)\n","max_encoder_seq_len = max([len(text) for text in input_texts])\n","max_decoder_seq_len = max([len(text) for text in target_texts])\n","\n","print('Number of samples:', len(input_texts))\n","print('Number of unique input tokens:', num_encoder_tokens)\n","print('Number of unique output tokens:', num_decoder_tokens)\n","print('Max seq length for inputs:', max_encoder_seq_len)\n","print('Max seq length for inputs:', max_decoder_seq_len)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tGTo71apND1u","executionInfo":{"status":"ok","timestamp":1671189004601,"user_tz":-330,"elapsed":596,"user":{"displayName":"Pramodi Perera","userId":"07641000018697658769"}},"outputId":"4bb71c60-89a8-424f-b570-6bc0d6ced2c5"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of samples: 10000\n","Number of unique input tokens: 71\n","Number of unique output tokens: 93\n","Max seq length for inputs: 15\n","Max seq length for inputs: 59\n"]}]},{"cell_type":"code","source":["### assign token indexes\n","input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n","output_token_index = dict([(char, i) for i, char in enumerate(target_characters)])"],"metadata":{"id":"5O0kYfQ8O7j7","executionInfo":{"status":"ok","timestamp":1671189007667,"user_tz":-330,"elapsed":4,"user":{"displayName":"Pramodi Perera","userId":"07641000018697658769"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["input_token_index"],"metadata":{"id":"AGShEEdORFBT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#shape = num_pairs, max_english_sentence_length, num_english_characters\n","encoder_input_data = np.zeros(\n","    (len(input_texts), max_encoder_seq_len, num_encoder_tokens), dtype='float32'\n",")\n","#shape (num_pairs, max_french_sentence_length, num_french_characters)\n","decoder_input_data  = np.zeros(\n","    (len(target_texts), max_decoder_seq_len, num_decoder_tokens), dtype='float32'\n",")\n","#same as decoder_input_data\n","decoder_target_data   = np.zeros(\n","    (len(target_texts), max_decoder_seq_len, num_decoder_tokens), dtype='float32'\n",")"],"metadata":{"id":"XaUpcSJXRGSv","executionInfo":{"status":"ok","timestamp":1671189014936,"user_tz":-330,"elapsed":3,"user":{"displayName":"Pramodi Perera","userId":"07641000018697658769"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["### one hot \n","for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","  # encoder\n","  for t, char in enumerate(input_text):\n","    encoder_input_data[i, t, input_token_index[char]] = 1.\n","  encoder_input_data[i, t+1:, input_token_index[' ']] = 1.\n","\n","  # decoder\n","  for t, char in enumerate(target_text):\n","    decoder_input_data[i, t, output_token_index[char]] = 1.\n","    if t>0:\n","      # decoder_target_data will be ahead by 1 timestep and will not include the start char\n","      decoder_target_data[i, t-1, output_token_index[char]] = 1.\n","  decoder_input_data[i, t+1:, output_token_index[' ']] = 1.\n","  decoder_target_data[i, t:, output_token_index[' ']] = 1.\n"],"metadata":{"id":"558cSHRKS3Zl","executionInfo":{"status":"ok","timestamp":1671189018936,"user_tz":-330,"elapsed":2,"user":{"displayName":"Pramodi Perera","userId":"07641000018697658769"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["encoder_input_data[0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RYduSWQfarqa","executionInfo":{"status":"ok","timestamp":1671189023102,"user_tz":-330,"elapsed":781,"user":{"displayName":"Pramodi Perera","userId":"07641000018697658769"}},"outputId":"56feeff6-966d-47a8-e864-47985b6d2e77"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(15, 71)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["encoder_input_data[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U4AseI0taw4w","executionInfo":{"status":"ok","timestamp":1671189025190,"user_tz":-330,"elapsed":6,"user":{"displayName":"Pramodi Perera","userId":"07641000018697658769"}},"outputId":"34049ac5-c114-4d7e-a169-94ff772d9fe6"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [1., 0., 0., ..., 0., 0., 0.],\n","       [1., 0., 0., ..., 0., 0., 0.],\n","       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["### define an input seq and process it\n","encoder_inputs = Input(shape=(None, num_encoder_tokens))\n","encoder = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","\n","encoder_states = [state_h, state_c] # we dont take encoder output\n"],"metadata":{"id":"lvvgbosCbKWt","executionInfo":{"status":"ok","timestamp":1671189030985,"user_tz":-330,"elapsed":3374,"user":{"displayName":"Pramodi Perera","userId":"07641000018697658769"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["decoder_inputs = Input(shape=(None, num_decoder_tokens))\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","\n","decoder_dense = Dense(num_decoder_tokens, activation = 'softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)"],"metadata":{"id":"kVamRoTHiEze","executionInfo":{"status":"ok","timestamp":1671189033825,"user_tz":-330,"elapsed":838,"user":{"displayName":"Pramodi Perera","userId":"07641000018697658769"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# model\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n","          batch_size= batch_size,\n","          epochs=100,\n","          validation_split=0.2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1MUbmR-Kl_Yd","executionInfo":{"status":"ok","timestamp":1671189203064,"user_tz":-330,"elapsed":161054,"user":{"displayName":"Pramodi Perera","userId":"07641000018697658769"}},"outputId":"a0ac1829-c5f1-4802-8581-9b41c76e9bc3"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","125/125 [==============================] - 10s 19ms/step - loss: 1.1397 - accuracy: 0.7371 - val_loss: 1.0589 - val_accuracy: 0.7157\n","Epoch 2/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.8155 - accuracy: 0.7797 - val_loss: 0.8185 - val_accuracy: 0.7745\n","Epoch 3/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.6653 - accuracy: 0.8160 - val_loss: 0.6912 - val_accuracy: 0.8025\n","Epoch 4/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.5708 - accuracy: 0.8349 - val_loss: 0.6284 - val_accuracy: 0.8197\n","Epoch 5/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.5220 - accuracy: 0.8475 - val_loss: 0.5933 - val_accuracy: 0.8270\n","Epoch 6/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.4873 - accuracy: 0.8572 - val_loss: 0.5672 - val_accuracy: 0.8360\n","Epoch 7/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.4594 - accuracy: 0.8643 - val_loss: 0.5294 - val_accuracy: 0.8448\n","Epoch 8/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.4356 - accuracy: 0.8708 - val_loss: 0.5182 - val_accuracy: 0.8479\n","Epoch 9/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.4152 - accuracy: 0.8761 - val_loss: 0.5091 - val_accuracy: 0.8504\n","Epoch 10/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.3969 - accuracy: 0.8814 - val_loss: 0.4951 - val_accuracy: 0.8551\n","Epoch 11/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.3802 - accuracy: 0.8862 - val_loss: 0.4774 - val_accuracy: 0.8592\n","Epoch 12/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.3647 - accuracy: 0.8905 - val_loss: 0.4669 - val_accuracy: 0.8628\n","Epoch 13/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.3500 - accuracy: 0.8950 - val_loss: 0.4628 - val_accuracy: 0.8635\n","Epoch 14/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.3363 - accuracy: 0.8989 - val_loss: 0.4568 - val_accuracy: 0.8657\n","Epoch 15/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.3240 - accuracy: 0.9024 - val_loss: 0.4533 - val_accuracy: 0.8668\n","Epoch 16/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.3117 - accuracy: 0.9059 - val_loss: 0.4480 - val_accuracy: 0.8692\n","Epoch 17/100\n","125/125 [==============================] - 1s 11ms/step - loss: 0.3005 - accuracy: 0.9092 - val_loss: 0.4449 - val_accuracy: 0.8704\n","Epoch 18/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.2896 - accuracy: 0.9128 - val_loss: 0.4470 - val_accuracy: 0.8710\n","Epoch 19/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.2792 - accuracy: 0.9156 - val_loss: 0.4418 - val_accuracy: 0.8725\n","Epoch 20/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.2698 - accuracy: 0.9185 - val_loss: 0.4455 - val_accuracy: 0.8721\n","Epoch 21/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.2604 - accuracy: 0.9213 - val_loss: 0.4409 - val_accuracy: 0.8746\n","Epoch 22/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.2517 - accuracy: 0.9240 - val_loss: 0.4441 - val_accuracy: 0.8744\n","Epoch 23/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.2434 - accuracy: 0.9262 - val_loss: 0.4434 - val_accuracy: 0.8747\n","Epoch 24/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.2351 - accuracy: 0.9290 - val_loss: 0.4450 - val_accuracy: 0.8752\n","Epoch 25/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.2274 - accuracy: 0.9310 - val_loss: 0.4505 - val_accuracy: 0.8752\n","Epoch 26/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.2202 - accuracy: 0.9332 - val_loss: 0.4506 - val_accuracy: 0.8755\n","Epoch 27/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.2129 - accuracy: 0.9354 - val_loss: 0.4469 - val_accuracy: 0.8763\n","Epoch 28/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.2062 - accuracy: 0.9374 - val_loss: 0.4555 - val_accuracy: 0.8759\n","Epoch 29/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.1997 - accuracy: 0.9396 - val_loss: 0.4594 - val_accuracy: 0.8760\n","Epoch 30/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.1937 - accuracy: 0.9412 - val_loss: 0.4599 - val_accuracy: 0.8764\n","Epoch 31/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.1879 - accuracy: 0.9430 - val_loss: 0.4668 - val_accuracy: 0.8760\n","Epoch 32/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.1823 - accuracy: 0.9444 - val_loss: 0.4732 - val_accuracy: 0.8755\n","Epoch 33/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.1766 - accuracy: 0.9459 - val_loss: 0.4710 - val_accuracy: 0.8764\n","Epoch 34/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.1715 - accuracy: 0.9477 - val_loss: 0.4793 - val_accuracy: 0.8759\n","Epoch 35/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.1665 - accuracy: 0.9490 - val_loss: 0.4799 - val_accuracy: 0.8764\n","Epoch 36/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.1616 - accuracy: 0.9504 - val_loss: 0.4870 - val_accuracy: 0.8759\n","Epoch 37/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.1570 - accuracy: 0.9518 - val_loss: 0.4897 - val_accuracy: 0.8755\n","Epoch 38/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.1526 - accuracy: 0.9534 - val_loss: 0.4981 - val_accuracy: 0.8750\n","Epoch 39/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.1488 - accuracy: 0.9542 - val_loss: 0.4996 - val_accuracy: 0.8755\n","Epoch 40/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.1447 - accuracy: 0.9556 - val_loss: 0.5057 - val_accuracy: 0.8750\n","Epoch 41/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.1406 - accuracy: 0.9567 - val_loss: 0.5094 - val_accuracy: 0.8752\n","Epoch 42/100\n","125/125 [==============================] - 2s 13ms/step - loss: 0.1372 - accuracy: 0.9577 - val_loss: 0.5122 - val_accuracy: 0.8753\n","Epoch 43/100\n","125/125 [==============================] - 2s 17ms/step - loss: 0.1337 - accuracy: 0.9586 - val_loss: 0.5205 - val_accuracy: 0.8753\n","Epoch 44/100\n","125/125 [==============================] - 2s 18ms/step - loss: 0.1304 - accuracy: 0.9595 - val_loss: 0.5247 - val_accuracy: 0.8744\n","Epoch 45/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.1271 - accuracy: 0.9607 - val_loss: 0.5270 - val_accuracy: 0.8748\n","Epoch 46/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.1242 - accuracy: 0.9615 - val_loss: 0.5302 - val_accuracy: 0.8751\n","Epoch 47/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.1210 - accuracy: 0.9625 - val_loss: 0.5404 - val_accuracy: 0.8752\n","Epoch 48/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.1181 - accuracy: 0.9632 - val_loss: 0.5428 - val_accuracy: 0.8739\n","Epoch 49/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.1155 - accuracy: 0.9641 - val_loss: 0.5434 - val_accuracy: 0.8760\n","Epoch 50/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.1128 - accuracy: 0.9647 - val_loss: 0.5536 - val_accuracy: 0.8741\n","Epoch 51/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.1104 - accuracy: 0.9655 - val_loss: 0.5573 - val_accuracy: 0.8743\n","Epoch 52/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.1078 - accuracy: 0.9662 - val_loss: 0.5612 - val_accuracy: 0.8741\n","Epoch 53/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.1055 - accuracy: 0.9670 - val_loss: 0.5655 - val_accuracy: 0.8743\n","Epoch 54/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.1032 - accuracy: 0.9674 - val_loss: 0.5651 - val_accuracy: 0.8741\n","Epoch 55/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.1009 - accuracy: 0.9683 - val_loss: 0.5768 - val_accuracy: 0.8733\n","Epoch 56/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0990 - accuracy: 0.9687 - val_loss: 0.5776 - val_accuracy: 0.8740\n","Epoch 57/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0970 - accuracy: 0.9693 - val_loss: 0.5931 - val_accuracy: 0.8724\n","Epoch 58/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0949 - accuracy: 0.9698 - val_loss: 0.5871 - val_accuracy: 0.8737\n","Epoch 59/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0931 - accuracy: 0.9702 - val_loss: 0.5939 - val_accuracy: 0.8731\n","Epoch 60/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0914 - accuracy: 0.9708 - val_loss: 0.5973 - val_accuracy: 0.8738\n","Epoch 61/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0897 - accuracy: 0.9713 - val_loss: 0.5989 - val_accuracy: 0.8729\n","Epoch 62/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0881 - accuracy: 0.9717 - val_loss: 0.6103 - val_accuracy: 0.8725\n","Epoch 63/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0861 - accuracy: 0.9721 - val_loss: 0.6107 - val_accuracy: 0.8732\n","Epoch 64/100\n","125/125 [==============================] - 2s 13ms/step - loss: 0.0844 - accuracy: 0.9728 - val_loss: 0.6117 - val_accuracy: 0.8729\n","Epoch 65/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0832 - accuracy: 0.9730 - val_loss: 0.6145 - val_accuracy: 0.8726\n","Epoch 66/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0813 - accuracy: 0.9737 - val_loss: 0.6250 - val_accuracy: 0.8727\n","Epoch 67/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0802 - accuracy: 0.9738 - val_loss: 0.6249 - val_accuracy: 0.8736\n","Epoch 68/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0786 - accuracy: 0.9744 - val_loss: 0.6359 - val_accuracy: 0.8721\n","Epoch 69/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0775 - accuracy: 0.9746 - val_loss: 0.6309 - val_accuracy: 0.8734\n","Epoch 70/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0761 - accuracy: 0.9750 - val_loss: 0.6377 - val_accuracy: 0.8732\n","Epoch 71/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0746 - accuracy: 0.9756 - val_loss: 0.6488 - val_accuracy: 0.8720\n","Epoch 72/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0735 - accuracy: 0.9759 - val_loss: 0.6496 - val_accuracy: 0.8721\n","Epoch 73/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0724 - accuracy: 0.9760 - val_loss: 0.6488 - val_accuracy: 0.8719\n","Epoch 74/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0708 - accuracy: 0.9765 - val_loss: 0.6494 - val_accuracy: 0.8731\n","Epoch 75/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0699 - accuracy: 0.9765 - val_loss: 0.6555 - val_accuracy: 0.8724\n","Epoch 76/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0688 - accuracy: 0.9770 - val_loss: 0.6599 - val_accuracy: 0.8721\n","Epoch 77/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0676 - accuracy: 0.9775 - val_loss: 0.6695 - val_accuracy: 0.8712\n","Epoch 78/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0667 - accuracy: 0.9777 - val_loss: 0.6624 - val_accuracy: 0.8726\n","Epoch 79/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0661 - accuracy: 0.9777 - val_loss: 0.6704 - val_accuracy: 0.8715\n","Epoch 80/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0645 - accuracy: 0.9783 - val_loss: 0.6723 - val_accuracy: 0.8720\n","Epoch 81/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0638 - accuracy: 0.9783 - val_loss: 0.6730 - val_accuracy: 0.8725\n","Epoch 82/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0629 - accuracy: 0.9786 - val_loss: 0.6836 - val_accuracy: 0.8721\n","Epoch 83/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0618 - accuracy: 0.9791 - val_loss: 0.6793 - val_accuracy: 0.8725\n","Epoch 84/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0607 - accuracy: 0.9793 - val_loss: 0.6834 - val_accuracy: 0.8724\n","Epoch 85/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0600 - accuracy: 0.9794 - val_loss: 0.6912 - val_accuracy: 0.8715\n","Epoch 86/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0591 - accuracy: 0.9795 - val_loss: 0.6914 - val_accuracy: 0.8720\n","Epoch 87/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0583 - accuracy: 0.9800 - val_loss: 0.6956 - val_accuracy: 0.8723\n","Epoch 88/100\n","125/125 [==============================] - 2s 13ms/step - loss: 0.0574 - accuracy: 0.9802 - val_loss: 0.6956 - val_accuracy: 0.8726\n","Epoch 89/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0569 - accuracy: 0.9804 - val_loss: 0.7094 - val_accuracy: 0.8711\n","Epoch 90/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0560 - accuracy: 0.9805 - val_loss: 0.7074 - val_accuracy: 0.8723\n","Epoch 91/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0552 - accuracy: 0.9807 - val_loss: 0.7107 - val_accuracy: 0.8718\n","Epoch 92/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0545 - accuracy: 0.9811 - val_loss: 0.7133 - val_accuracy: 0.8716\n","Epoch 93/100\n","125/125 [==============================] - 2s 13ms/step - loss: 0.0538 - accuracy: 0.9813 - val_loss: 0.7166 - val_accuracy: 0.8716\n","Epoch 94/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0534 - accuracy: 0.9812 - val_loss: 0.7189 - val_accuracy: 0.8722\n","Epoch 95/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0527 - accuracy: 0.9813 - val_loss: 0.7221 - val_accuracy: 0.8715\n","Epoch 96/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0521 - accuracy: 0.9818 - val_loss: 0.7223 - val_accuracy: 0.8718\n","Epoch 97/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0513 - accuracy: 0.9818 - val_loss: 0.7240 - val_accuracy: 0.8720\n","Epoch 98/100\n","125/125 [==============================] - 2s 12ms/step - loss: 0.0508 - accuracy: 0.9819 - val_loss: 0.7283 - val_accuracy: 0.8709\n","Epoch 99/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0499 - accuracy: 0.9821 - val_loss: 0.7356 - val_accuracy: 0.8720\n","Epoch 100/100\n","125/125 [==============================] - 1s 12ms/step - loss: 0.0494 - accuracy: 0.9825 - val_loss: 0.7290 - val_accuracy: 0.8728\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f3cb078fc70>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# define sampling models\n","encoder_model = Model(encoder_inputs, encoder_states)\n","\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs] + decoder_states)"],"metadata":{"id":"LcGC-MolojCt","executionInfo":{"status":"ok","timestamp":1671189654939,"user_tz":-330,"elapsed":756,"user":{"displayName":"Pramodi Perera","userId":"07641000018697658769"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["#reverse-lookup token index to decode seq back to somthing readable\n","reverse_input_char_index = dict(\n","    (i, char) for char, i in input_token_index.items())\n","reverse_target_char_index = dict(\n","    (i, char) for char, i in output_token_index.items())\n","\n","\n","def decode_sequence(input_seq):\n","    # Encode the input as state vectors.\n","    states_value = encoder_model.predict(input_seq)\n","\n","    # Generate empty target sequence of length 1.\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    # Populate the first character of target sequence with the start character.\n","    target_seq[0, 0, output_token_index['\\t']] = 1.\n","\n","    # Sampling loop for a batch of sequences\n","    # (to simplify, here we assume a batch of size 1).\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict(\n","            [target_seq] + states_value)\n","\n","        # Sample a token\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = reverse_target_char_index[sampled_token_index]\n","        decoded_sentence += sampled_char\n","\n","        # Exit condition: either hit max length\n","        # or find stop character.\n","        if (sampled_char == '\\n' or\n","           len(decoded_sentence) > max_decoder_seq_len):\n","            stop_condition = True\n","\n","        # Update the target sequence (of length 1).\n","        target_seq = np.zeros((1, 1, num_decoder_tokens))\n","        target_seq[0, 0, sampled_token_index] = 1.\n","\n","        # Update states\n","        states_value = [h, c]\n","\n","    return decoded_sentence\n","\n","for seq_index in range(30):\n","  input_seq = encoder_input_data[seq_index: seq_index + 1]\n","  decoded_sentence = decode_sequence(input_seq)\n","  print('-')\n","  print('Input sentence:', input_texts[seq_index])\n","  print('Decoded sentence:', decoded_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lm42rRLerEoG","executionInfo":{"status":"ok","timestamp":1671190316922,"user_tz":-330,"elapsed":16029,"user":{"displayName":"Pramodi Perera","userId":"07641000018697658769"}},"outputId":"b4642736-d0da-4bd3-bca1-b79857fba2e7"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 321ms/step\n","1/1 [==============================] - 0s 318ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 16ms/step\n","-\n","Input sentence: Go.\n","Decoded sentence: Va !\n","\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 15ms/step\n","-\n","Input sentence: Go.\n","Decoded sentence: Va !\n","\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 16ms/step\n","-\n","Input sentence: Go.\n","Decoded sentence: Va !\n","\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","-\n","Input sentence: Go.\n","Decoded sentence: Va !\n","\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","-\n","Input sentence: Hi.\n","Decoded sentence: Salut.\n","\n","1/1 [==============================] - 0s 13ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","-\n","Input sentence: Hi.\n","Decoded sentence: Salut.\n","\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 14ms/step\n","-\n","Input sentence: Run!\n","Decoded sentence: Filez !\n","\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 15ms/step\n","-\n","Input sentence: Run!\n","Decoded sentence: Filez !\n","\n","1/1 [==============================] - 0s 13ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","-\n","Input sentence: Run!\n","Decoded sentence: Filez !\n","\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","-\n","Input sentence: Run!\n","Decoded sentence: Filez !\n","\n","1/1 [==============================] - 0s 13ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 16ms/step\n","-\n","Input sentence: Run!\n","Decoded sentence: Filez !\n","\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 14ms/step\n","-\n","Input sentence: Run!\n","Decoded sentence: Filez !\n","\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 17ms/step\n","-\n","Input sentence: Run!\n","Decoded sentence: Filez !\n","\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","-\n","Input sentence: Run!\n","Decoded sentence: Filez !\n","\n","1/1 [==============================] - 0s 13ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","-\n","Input sentence: Run.\n","Decoded sentence: Fuyez !\n","\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 16ms/step\n","-\n","Input sentence: Run.\n","Decoded sentence: Fuyez !\n","\n","1/1 [==============================] - 0s 13ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 17ms/step\n","-\n","Input sentence: Run.\n","Decoded sentence: Fuyez !\n","\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","-\n","Input sentence: Run.\n","Decoded sentence: Fuyez !\n","\n","1/1 [==============================] - 0s 13ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","-\n","Input sentence: Run.\n","Decoded sentence: Fuyez !\n","\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","-\n","Input sentence: Run.\n","Decoded sentence: Fuyez !\n","\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","-\n","Input sentence: Run.\n","Decoded sentence: Fuyez !\n","\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 27ms/step\n","-\n","Input sentence: Run.\n","Decoded sentence: Fuyez !\n","\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 24ms/step\n","-\n","Input sentence: Who?\n","Decoded sentence: Qui ?\n","\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 22ms/step\n","-\n","Input sentence: Wow!\n","Decoded sentence: Waouh !\n","\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 28ms/step\n","-\n","Input sentence: Wow!\n","Decoded sentence: Waouh !\n","\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","-\n","Input sentence: Wow!\n","Decoded sentence: Waouh !\n","\n","1/1 [==============================] - 0s 13ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 15ms/step\n","-\n","Input sentence: Duck!\n","Decoded sentence: Baissez-vous !\n","\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","-\n","Input sentence: Duck!\n","Decoded sentence: Baissez-vous !\n","\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 16ms/step\n","-\n","Input sentence: Duck!\n","Decoded sentence: Baissez-vous !\n","\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","-\n","Input sentence: Fire!\n","Decoded sentence: Au feu !\n","\n"]}]}]}